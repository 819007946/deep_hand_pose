# The train/test net protocol buffer definition
#net: "examples/NYU_HANDS/regressor.prototxt"
#net: "examples/NYU_HANDS/heatmap.prototxt"
#net: "examples/NYU_HANDS/oxford_hm.prototxt"
#net: "examples/NYU_HANDS/tompson.prototxt"
#net: "examples/NYU_HANDS/oberweger.prototxt"
net: "examples/NYU_HANDS/oberweger-pca.prototxt"
#net: "examples/NYU_HANDS/baseline.prototxt"
# test_iter specifies how many forward passes the test should carry out.
# In the case of MNIST, we have test batch size 100 and 100 test iterations,
# covering the full 10,000 testing images.
test_iter: 100
# Carry out testing every 500 training iterations.
test_interval: 500
test_initialization: true
# The base learning rate, momentum and the weight decay of the network.
base_lr: 0.000005
#momentum: 0.0
momentum: 0.9
# Weight decay corresponds to the L2 regularizers's lambda
#weight_decay: 0.0005
weight_decay: 0
# The learning rate policy
lr_policy: "inv"
gamma: 0.0001
power: 0.75
# Display every 100 iterations
display: 25
average_loss: 25
# The maximum number of iterations
max_iter: 40000
max_seconds: 21600
# snapshot intermediate results
snapshot: 5000
snapshot_prefix: "out/network"
# solver mode: CPU or GPU
solver_type: SGD
#solver_type: ADAGRAD
solver_mode: GPU
device_id: 0
